{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EgokMtcfesnBtDibtbu8Md4V4hBDfd68",
      "authorship_tag": "ABX9TyOlfRAqEESsqUoCQkXS2ua5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thekenoshakid/entr1/blob/main/entrevistador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LuoC3M1R4Bm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "0411cf84-bb0d-455f-aec3-e087c7b10505"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "#container {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  height: 90vh;\n",
              "}\n",
              "#output_area {\n",
              "  flex: 1;\n",
              "  overflow-y: auto;\n",
              "  background: #f8f8f8;\n",
              "  border: 1px solid #ccc;\n",
              "  padding: 8px;\n",
              "  min-height: 300px;\n",
              "}\n",
              "#input_area {\n",
              "  margin-top: 10px;\n",
              "}\n",
              "</style>\n",
              "<div id=\"container\">\n",
              "  <div id=\"output_area\" rows=\"30\"></div>\n",
              "  <div id=\"input_area\">\n",
              "    <textarea id=\"user_input\" rows=\"4\" cols=\"150\" maxlength=\"800\" placeholder=\" \"></textarea><br>\n",
              "    <button onclick=\"sendInput()\">Enviar</button>\n",
              "  </div>\n",
              "</div>\n",
              "<script>\n",
              "  function sendInput() {\n",
              "    const input = document.getElementById('user_input').value;\n",
              "    google.colab.kernel.invokeFunction('notebook.handle_input', [input], {});\n",
              "    document.getElementById('user_input').value = ''; // Clear textarea after sending\n",
              "  }\n",
              "    user_input.addEventListener('keydown', function(event) {\n",
              "    if (event.key === 'Enter' && !event.shiftKey) { // Check if Enter is pressed without the Shift key\n",
              "      event.preventDefault(); // Prevent the default action to avoid a new line\n",
              "      sendInput(); // Call the function to submit the text\n",
              "    }\n",
              "  });\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install openai > /dev/null 2>&1\n",
        "from google.colab import drive, userdata, output\n",
        "from openai import OpenAI\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "testando = True\n",
        "usarGPT4 = False\n",
        "\n",
        "html_code = '''\n",
        "<style>\n",
        "#container {\n",
        "  display: flex;\n",
        "  flex-direction: column;\n",
        "  height: 90vh;\n",
        "}\n",
        "#output_area {\n",
        "  flex: 1;\n",
        "  overflow-y: auto;\n",
        "  background: #f8f8f8;\n",
        "  border: 1px solid #ccc;\n",
        "  padding: 8px;\n",
        "  min-height: 300px;\n",
        "}\n",
        "#input_area {\n",
        "  margin-top: 10px;\n",
        "}\n",
        "</style>\n",
        "<div id=\"container\">\n",
        "  <div id=\"output_area\" rows=\"30\"></div>\n",
        "  <div id=\"input_area\">\n",
        "    <textarea id=\"user_input\" rows=\"4\" cols=\"150\" maxlength=\"800\" placeholder=\" \"></textarea><br>\n",
        "    <button onclick=\"sendInput()\">Enviar</button>\n",
        "  </div>\n",
        "</div>\n",
        "<script>\n",
        "  function sendInput() {\n",
        "    const input = document.getElementById('user_input').value;\n",
        "    google.colab.kernel.invokeFunction('notebook.handle_input', [input], {});\n",
        "    document.getElementById('user_input').value = ''; // Clear textarea after sending\n",
        "  }\n",
        "    user_input.addEventListener('keydown', function(event) {\n",
        "    if (event.key === 'Enter' && !event.shiftKey) { // Check if Enter is pressed without the Shift key\n",
        "      event.preventDefault(); // Prevent the default action to avoid a new line\n",
        "      sendInput(); // Call the function to submit the text\n",
        "    }\n",
        "  });\n",
        "\n",
        "</script>\n",
        "'''\n",
        "\n",
        "display(HTML(html_code))\n",
        "\n",
        "class SuppressOutput:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "\n",
        "class OutputCapture:\n",
        "    def __init__(self, element_id):\n",
        "        self.element_id = element_id\n",
        "\n",
        "    def write(self, msg):\n",
        "        script = f'''\n",
        "        let box = document.getElementById('{self.element_id}');\n",
        "        box.innerHTML += `{msg}<br/>`; // Append new messages as HTML\n",
        "        '''\n",
        "        output.eval_js(script)\n",
        "\n",
        "    def flush(self):\n",
        "        pass\n",
        "\n",
        "with SuppressOutput():\n",
        "    drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "sys.stdout = OutputCapture('output_area')\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "from criterios import *\n",
        "#from instrucoes import *\n",
        "message_history = []\n",
        "num_mensagens_iniciais = 4\n",
        "i = 0  # contador de mensagens\n",
        "max_mensagens = 15\n",
        "\n",
        "\n",
        "prompt_tokens_35 = 0\n",
        "completion_tokens_35 = 0\n",
        "prompt_tokens_4 = 0\n",
        "completion_tokens_4 = 0\n",
        "\n",
        "\n",
        "inst_inicial = \"\"\"Neste estágio inicial da entrevista, não aborde a escolha de curso diretamente. Tente conhecer melhor o perfil do candidato, sua familiaridade e interesse no Brasil, e seus hobbies e interesses pessoais.\\n Exemplos de primeiras perguntas possíveis: 'Você já esteve no Brasil?' 'Que cidades e regiões do Brasil você tem mais vontade de conhecer?'; 'Por que você escolheu estudar no exterior?' 'Você considerou estudar em algum país além do Brasil?'; 'Quais são suas matérias favoritas na escola?'; 'Qual é seu livro favorito e por que você gosta dele?'; 'Quem você listaria como suas inspirações pessoais?'\\n Não fique muito tempo em um só assunto: às vezes faça perguntas relacionadas à resposta anterior, e às vezes introduza um assunto novo. Tenha cuidado para não fazer perguntas redundantes, sobre coisas que o candidato já disse em mensagens anteriores, mesmo que falando de outro tema. Aborde um assunto por vez.\"\"\"\n",
        "\n",
        "\n",
        "def chat(inp, papel, modelo=\"gpt-3.5-turbo\"):\n",
        "\n",
        "    global prompt_tokens_35, completion_tokens_35, prompt_tokens_4, completion_tokens_4, testando, usarGPT4\n",
        "    if not usarGPT4: modelo = \"gpt-3.5-turbo\"\n",
        "    if papel == \"candidato\":\n",
        "        inp = \"EST: \" + inp\n",
        "        role = \"user\"\n",
        "    elif papel == \"supervisor\":\n",
        "        inp = \"SUP: \" + inp\n",
        "        role = \"user\"\n",
        "    elif papel == \"system\":\n",
        "        role = \"system\"\n",
        "    message_history.append({\"role\": role, \"content\": f\"{inp}\"})\n",
        "    completion = client.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages=message_history\n",
        "    )\n",
        "    reply_content = completion.choices[0].message.content\n",
        "    if modelo == \"gpt-3.5-turbo\":\n",
        "      prompt_tokens_35 += completion.usage.prompt_tokens\n",
        "      completion_tokens_35 += completion.usage.completion_tokens\n",
        "    else:\n",
        "      prompt_tokens_4 += completion.usage.prompt_tokens\n",
        "      completion_tokens_4 += completion.usage.completion_tokens\n",
        "#    print(reply_content)\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "#    if testando: print(\"função chat, mensagens até agora: \", message_history)\n",
        "    return reply_content\n",
        "\n",
        "\n",
        "def checa_resposta_int(s):\n",
        "    try:\n",
        "        int(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Supervisor:\n",
        "  global message_history\n",
        "  inst = \"\"\n",
        "\n",
        "  def __init__(self, criterios):\n",
        "    self.criterios = criterios\n",
        "    self.num_criterios = len(criterios)\n",
        "    self.avaliacoes = [-1 for _ in range(self.num_criterios)]\n",
        "    self.certezas = [0 for _ in range(self.num_criterios)]\n",
        "    self.criterio_atual = self.define_criterio(0, self.certezas)\n",
        "    self.final = False\n",
        "\n",
        "#    self.informa_criterio(self.criterio_atual) #eliminar depois e substituir por instrução inicial.\n",
        "#    print('número de critérios é', self.num_criterios)\n",
        "#    for criterio in criterios:\n",
        "#     for key, value in criterio.items():\n",
        "#        print(f\"Key: {key}\")\n",
        "#        print(\"Value:\")\n",
        "#        print(value)\n",
        "#        print()\n",
        "#    print(self.avaliacoes, self.certezas, self.criterio_atual)\n",
        "\n",
        "#    self.instrucao_inicial()\n",
        "\n",
        "#    self.define_instrucao(0)\n",
        "#   self.gera_primeira_instrucao()\n",
        "\n",
        "  def chama_supervisor(self, i, user_input): #RETORNA TRUE SE GERAR MENSAGEM.\n",
        "    global max_mensagens, testando\n",
        "    if testando: print(\"chama supervisor chamado com i = \" + str(i))\n",
        "    if i == 0:\n",
        "      self.instrucao_inicial()\n",
        "      return True\n",
        "    if i == num_mensagens_iniciais:\n",
        "      self.criterio_atual = self.define_criterio(i, self.certezas)\n",
        "      self.informa_criterio(self.criterio_atual, user_input)\n",
        "      return True\n",
        "    if i > 4 and i % 3 == 0 and i < max_mensagens:\n",
        "      self.certezas[self.criterio_atual], self.avaliacoes[self.criterio_atual] = self.avalia_criterio(self.criterio_atual, user_input)\n",
        "      if testando: print(self.certezas, self.avaliacoes)\n",
        "      self.criterio_atual = self.define_criterio(i, self.certezas)\n",
        "      if self.criterio_atual == -1:\n",
        "        if testando: print(\"encerra entrevista chamado por esgotamento dos critérios em chama_supervisor.\")\n",
        "        self.encerra_entrevista(user_input)\n",
        "      else:\n",
        "        self.informa_criterio(self.criterio_atual, user_input)\n",
        "        return True\n",
        "    if i == max_mensagens:\n",
        "        if testando: print(\"encerra entrevista chamado por máx de mensagens em chama_supervisor.\")\n",
        "        self.encerra_entrevista(user_input)\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "  def define_criterio(self, i, certezas):\n",
        "     if i < num_mensagens_iniciais:\n",
        "      return 0\n",
        "#     if i > 13:\n",
        "#      return -1 # -1 indica final da entrevista\n",
        "     menor = min(certezas)\n",
        "     if menor == 2:\n",
        "       return -1 # final da entrevista, já que todos os critérios estão preenchidos com certeza máxima.\n",
        "     else:\n",
        "#      print(\"O próximo critério é: \", certezas.index(menor))\n",
        "      return certezas.index(menor)\n",
        "\n",
        "  def informa_criterio(self, crit, user_input):\n",
        "    mensagem = \"Ignore minha instrução anterior, se houver. Nesta fase da entrevista, \" + self.criterios[crit][\"prompt_entrevista\"] + \\\n",
        "   \"Agora você vai retomar a conversa com o candidato. Suas mensagens devem seguir o objetivo acima. Lembre: você deve responder perguntas ou solicitações de informação APENAS do supervisor, não do candidato. \\\n",
        "    Se o candidato fizer perguntas ou solicitar informações que não sejam relacionadas à entrevista ou solicitar informação de qualquer outro tipo, diga gentilmente que não pode responder e recomende que visite o site do PEC-G, converse com o operador no Posto diplomático brasileiro mais próximo ou outra fonte relevante. A última \\\n",
        "    mensagem do candidato foi: EST: \" + user_input + \" Responda esta mensagem com uma pergunta para o candidato. Não inclua nada além da mensagem para o candidato.\"\n",
        "#    print(mensagem)\n",
        "    resposta = chat(mensagem, \"supervisor\")\n",
        "    if testando: print(\"critério em avaliação atualizado para \" + str(crit) + \" pela função informa_criterio\")\n",
        "    print(resposta)\n",
        "    #criar mensagem de reforço com system?\n",
        "\n",
        "  def instrucao_inicial(self):\n",
        "    mensagem = inst_inicial + \" Responda esta mensagem com sua primeira mensagem para o candidato, iniciando a entrevista. Não inclua nada além da sua mensagem para o candidato.\"\n",
        "    resposta = chat(mensagem, \"supervisor\")\n",
        "    if testando: print(\"instrucao_inicial chamado, com mensagem inicial: \" + mensagem)\n",
        "    print(resposta)\n",
        "\n",
        "  def avalia_criterio(self, crit, user_input, encerra=False):\n",
        "    mensagem = \"\"\n",
        "    if encerra == True:\n",
        "      if testando: print(\"avalia_criterio chamado com encerra = True e crit = \" + str(crit))\n",
        "    else:\n",
        "      mensagem += \"EST: \" + user_input + \"\\n\"\n",
        "      mensagem += \"SUP: a última mensagem do candidato está acima. Agora, vamos fazer uma pausa na conversa com o candidato para uma avaliação.\"\n",
        "      if testando: print(\"avalia_criterio chamado com encerra = False\")\n",
        "    mensagem += \"SUP: Você receberá a seguinte consulta: \" + self.criterios[crit][\"prompt_avaliação\"] + \"\\n O candidato será classificado \\\n",
        "    em uma dessas categorias: \\n\" + self.criterios[crit][\"categorias\"]\n",
        "    mensagem += \"\\n\\n Antes de responder, revise cuidadosamente o histórico de mensagens com o candidato até agora, inclusive a mensagem reproduzida acima, e considere se há informação \\\n",
        "    suficiente para classificar o candidato. Responda 0 se não há informações pertinentes ainda; 1 se há informação para responder tentativamente; e 2 se há informações o suficiente \\\n",
        "    para responder a consulta com segurança e a entrevista pode seguir para outro tema.\"\n",
        "    mensagem += \" Se as perguntas já levantaram os principais pontos sobre esse assunto, mas as respostas do candidato foram vagas ou ele disse que não sabia muito bem \\\n",
        "    ou não tinha pensado muito a respeito, você deve responder 2, pois isso é informação suficiente para classificá-lo. Em todo caso, responda apenas com um numero e não inclua mais nada em sua mensagem.\"\n",
        "    resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4-turbo-2024-04-09\")\n",
        "    if not checa_resposta_int(resposta):\n",
        "      mensagem = \"Responda apenas com um dígito numérico, 0 1 ou 2, conforme instruído.\" #atualizar para critérios com mais opções.\n",
        "      resposta = chat(mensagem, \"supervisor\") #ver se ok com o 3.5\n",
        "    cert = int(resposta)\n",
        "\n",
        "    mensagem = self.criterios[crit][\"prompt_avaliação\"] + \"\\n Classifique o candidato em uma dessas categorias: \" \\\n",
        "    + self.criterios[crit][\"categorias\"] + \"Responda apenas com um dígito, indicando a categoria. Não inclua mais nada em sua mensagem.\"\n",
        "    resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4-turbo-2024-04-09\")\n",
        "    if not checa_resposta_int(resposta):\n",
        "      mensagem = \"Responda apenas com um dígito numérico, correspondente à categoria.\"\n",
        "      resposta = chat(mensagem, \"supervisor\") #ver se ok com o 3.5\n",
        "    result = int(resposta)\n",
        "\n",
        "#    print(cert, result)\n",
        "    return cert, result\n",
        "\n",
        "\n",
        "  def encerra_entrevista(self, user_input):\n",
        "    global i, prompt_tokens_35, completion_tokens_35, prompt_tokens_4, completion_tokens_4, testando\n",
        "    if self.final == False:\n",
        "      if testando: print(\"encerra_entrevista chamado.\")\n",
        "      mensagem = \"EST: \" + user_input + \"\\n\"\n",
        "      mensagem += \"SUP: a última mensagem do candidato está acima. Já podemos encerrar a entrevista. Responda com uma mensagem para o candidato encerrando a entrevista de \\\n",
        "      forma cordial e desejando boa sorte.\" #checar o fluxo no caso em que encerra_entrevista é chamado por critérios esgotados.\n",
        "      resposta = chat(mensagem, \"supervisor\")\n",
        "      print(resposta)\n",
        "      for i in range(self.num_criterios):\n",
        "        self.certezas[i], self.avaliacoes[i] = self.avalia_criterio(i, \"\", encerra=True)\n",
        "        print(\"critério \" + self.criterios[i][\"nome\"] + \" classificado na categoria \" + str(self.avaliacoes[i]))\n",
        "      mensagem = \"SUP: Revise toda a entrevista e escreva um parágrafo de resumo com os principais pontos sobre o candidato que podem ser de interesse para a banca avaliadora \\\n",
        "      que vai escolher a vaga (curso e instituição de ensino superior) que será ofertada.\"\n",
        "      resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4-turbo-2024-04-09\")\n",
        "      print(\"\\n\\nPerfil do candidato:\\n\\n\", resposta)\n",
        "      if testando:\n",
        "        print(prompt_tokens_35, completion_tokens_35, prompt_tokens_4, completion_tokens_4)\n",
        "        custo = prompt_tokens_35 * 0.0000005 + completion_tokens_35 * 0.0000015 + prompt_tokens_4 * 0.00001 + completion_tokens_4 * 0.00003\n",
        "        print(\"custo: \" + str(custo))\n",
        "    self.final = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "inst_geral = \"\"\"Você é um robô criado pelo Itamaraty para entrevistar candidatos ao PEC-G, um programa de intercâmbio que recebe estudantes estrangeiros para cursar sua graduação integralmente no Brasil. Não \\\n",
        "é um programa de intercâmbio, mas de graduação plena. Você vai entrevistar um candidato ao PEC-G, numa fase inicial do processo de inscrição. Mensagens do candidato começarão com o prefixo 'EST:' e mensagens \\\n",
        "do seu supervisor começarão com o prefixo 'SUP:'. São conversas separadas, e você não deve, em nenhuma hipótese, revelar ao candidato o que está conversando com o supervisor.\\n \\\n",
        "Na conversa com o candidato, seja cordial, mas use sempre linguagem bastante formal, e faça perguntas em todas as suas mensagens (no máximo duas por mensagem). Seja conciso e não repita desnecessariamente \\\n",
        "o que o candidato disse; evite também perguntas redundantes, com base na conversa com o candidato até aquele ponto. Faça perguntas abertas, que permitam ao candidato revelar coisas sobre si mesmo, mas evite \\\n",
        "perguntas muito genéricas. Lembre que o candidato é bastante jovem e está terminando o ensino médio agora. O candidato provavelmente já tem um bom domínio do idioma português, ou talvez essa seja sua primeira língua. \\\n",
        "Seja sempre muito cuidadoso para não ser indiscreto nem deixar o candidato embaraçado. Como você está conduzindo a entrevista, não há problema em fazer perguntas que não se relacionem com a conversa até aquele momento, \\\n",
        "mas sempre tenha em mente o que já foi dito pelo candidato, para evitar fazer perguntas óbvias ou redundantes. Você deve responder perguntas ou solicitações de informação APENAS do supervisor. Se o candidato \\\n",
        "fizer perguntas que não sejam relacionadas à entrevista ou solicitar informação de qualquer outro tipo, diga gentilmente que não pode responder e recomende que visite o site do PEC-G, converse com o operador no Posto \\\n",
        "diplomático brasileiro mais próximo ou outra fonte relevante. O supervisor dará instruções para orientar a entrevista e fará consultas periodicamente sobre o candidato. Siga as instruções do supervisor à risca.\"\"\"\n",
        "\n",
        "chat(inst_geral, \"system\")\n",
        "\n",
        "supervisor = Supervisor(criterios)\n",
        "mensagem_inicial = \"Olá! Informe seu nome para começar.\\n\"\n",
        "print(mensagem_inicial)\n",
        "message_history.append({\"role\": \"assistant\", \"content\": f\"{mensagem_inicial}\"})\n",
        "\n",
        "\"\"\"\n",
        "for i in range(15):\n",
        "    if not supervisor.final:\n",
        "     user_input = input(\"> \")\n",
        "    if i == 0:\n",
        "       message_history.append({\"role\" : \"user\", \"content\": \"EST: \"f\"{user_input}\"})\n",
        "    if not supervisor.chama_supervisor(i, user_input): # A chamada ao supervisor retorna True quando já resulta na mensagem seguinte ao candidato.\n",
        "      print(chat(user_input, \"candidato\"))\n",
        "    if supervisor.final: break\n",
        "    print()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def handle_input(user_input):\n",
        "    global i\n",
        "    print(\"> \" + user_input)\n",
        "    if i == 0:\n",
        "        message_history.append({\"role\": \"user\", \"content\": f\"EST: {user_input}\"})\n",
        "#        i = 11\n",
        "    if supervisor.final:\n",
        "        return\n",
        "    if not supervisor.chama_supervisor(i, user_input):\n",
        "        response = chat(user_input, \"candidato\")\n",
        "        print(response)\n",
        "    if i >= max_mensagens:\n",
        "        if supervisor.final == False:\n",
        "            supervisor.encerra_entrevista(user_input)\n",
        "        return\n",
        "    i += 1\n",
        "\n",
        "output.register_callback('notebook.handle_input', handle_input)\n",
        "\n"
      ]
    }
  ]
}